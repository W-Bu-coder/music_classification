{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3012995c-a2f5-455c-ae05-a730ec6ee281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è®¾å¤‡: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']  \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# è®¾ç½®å›¾è¡¨æ ·å¼\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "DATA_DIR = \"fma_metadata\"  \n",
    "AUDIO_DIR = \"fma_small\"   \n",
    "FEATURE_PATH = 'features'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "150b38fe-743f-4100-b48b-a33d62e22b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹æ•°æ®: 106574 é¦–æ­Œæ›²\n",
      "æ¸…ç†åæ•°æ®: 49598 é¦–æ­Œæ›²\n"
     ]
    }
   ],
   "source": [
    "def load_metadata():\n",
    "    tracks = pd.read_csv(os.path.join(DATA_DIR, \"tracks.csv\"), header=[0, 1], index_col=0)\n",
    "    genres = pd.read_csv(os.path.join(DATA_DIR, \"genres.csv\"), index_col=0)\n",
    "    features = pd.read_csv(os.path.join(DATA_DIR, \"features.csv\"), header=[0, 1, 2], index_col=0)\n",
    "    return tracks, genres, features\n",
    "\n",
    "def process_tracks_data(tracks):\n",
    "    # æå–å…³é”®åˆ—\n",
    "    track_data = pd.DataFrame({\n",
    "        'track_id': tracks.index,\n",
    "        'title': tracks[('track', 'title')],\n",
    "        'duration': tracks[('track', 'duration')],\n",
    "        'genre_top': tracks[('track', 'genre_top')],\n",
    "        'genres': tracks[('track', 'genres')],\n",
    "        'listens': tracks[('track', 'listens')],\n",
    "        'bit_rate': tracks[('track', 'bit_rate')],\n",
    "        'interest': tracks[('track', 'interest')]\n",
    "    })\n",
    "    \n",
    "    print(f\"åŸå§‹æ•°æ®: {len(track_data)} é¦–æ­Œæ›²\")\n",
    "    \n",
    "    # æ¸…ç†æ•°æ®\n",
    "    # ç§»é™¤æ²¡æœ‰genre_topæ ‡ç­¾çš„æ•°æ®\n",
    "    track_data = track_data.dropna(subset=['genre_top'])\n",
    "    track_data = track_data[track_data['genre_top'] != 0]\n",
    "    \n",
    "    # è½¬æ¢æ•°æ®ç±»å‹\n",
    "    track_data['duration'] = pd.to_numeric(track_data['duration'], errors='coerce')\n",
    "    track_data['listens'] = pd.to_numeric(track_data['listens'], errors='coerce')\n",
    "    genre_name_to_id = {}\n",
    "    for gid, row in genres.iterrows():\n",
    "        genre_name_to_id[row['title']] = gid\n",
    "    \n",
    "    # æ˜ å°„æµæ´¾åç§°åˆ°ID\n",
    "    def map_genre_name_to_id(genre_name):\n",
    "        if pd.isna(genre_name):\n",
    "            return np.nan\n",
    "        if isinstance(genre_name, str):\n",
    "            return genre_name_to_id.get(genre_name, np.nan)\n",
    "        else:\n",
    "            return genre_name\n",
    "    \n",
    "    track_data['genre_top'] = track_data['genre_top'].apply(map_genre_name_to_id)\n",
    "    \n",
    "    # ç§»é™¤æ— æ³•æ˜ å°„çš„æµæ´¾\n",
    "    track_data = track_data.dropna(subset=['genre_top'])\n",
    "    \n",
    "    print(f\"æ¸…ç†åæ•°æ®: {len(track_data)} é¦–æ­Œæ›²\")\n",
    "    return track_data\n",
    "\n",
    "tracks, genres, features = load_metadata()\n",
    "track_data = process_tracks_data(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7707683e-f37f-4616-8732-2b3be634ba8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ‰«æéŸ³é¢‘ç›®å½•: fma_small\n",
      "   æ‰¾åˆ° 7999 ä¸ªéŸ³é¢‘æ–‡ä»¶\n",
      "   æ€»å¤§å°: 7.43 GB\n"
     ]
    }
   ],
   "source": [
    "def scan_audio_files(audio_dir):\n",
    "    \"\"\"æ‰«æéŸ³é¢‘ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰å¯ç”¨çš„mp3æ–‡ä»¶\"\"\"\n",
    "    print(f\"ğŸ“‚ æ‰«æéŸ³é¢‘ç›®å½•: {audio_dir}\")\n",
    "    \n",
    "    if not os.path.exists(audio_dir):\n",
    "        print(f\"âŒ éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {audio_dir}\")\n",
    "        return {}\n",
    "    \n",
    "    audio_files = {}\n",
    "    total_size = 0\n",
    "    \n",
    "    # éå†æ‰€æœ‰å­æ–‡ä»¶å¤¹\n",
    "    for root, dirs, files in os.walk(audio_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # ä»æ–‡ä»¶åæå–track_id\n",
    "                try:\n",
    "                    track_id = int(file.split('.')[0])\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    \n",
    "                    audio_files[track_id] = {\n",
    "                        'path': file_path,\n",
    "                        'size_bytes': file_size,\n",
    "                        'size_kb': file_size / 1024,\n",
    "                        'size_mb': file_size / (1024 * 1024)\n",
    "                    }\n",
    "                    total_size += file_size\n",
    "                    \n",
    "                except ValueError:\n",
    "                    # æ–‡ä»¶åä¸æ˜¯æ•°å­—ï¼Œè·³è¿‡\n",
    "                    continue\n",
    "    \n",
    "    print(f\"   æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\")\n",
    "    print(f\"   æ€»å¤§å°: {total_size / (1024**3):.2f} GB\")\n",
    "    \n",
    "    return audio_files\n",
    "\n",
    "# æ‰«æéŸ³é¢‘æ–‡ä»¶\n",
    "audio_files_info = scan_audio_files(AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb1cf56-0eca-4f70-aa97-94eb9c8c8908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… è¿‡æ»¤ç»“æœ:\n",
      "   åŸå§‹track_data: 49598\n",
      "   æœ€ç»ˆå¯ç”¨æ•°æ®: 7996\n"
     ]
    }
   ],
   "source": [
    "def filter_valid_audio_files(audio_files_info, track_data, min_size_kb=10, max_size_kb=20000):\n",
    "    \"\"\"è¿‡æ»¤å‡ºå¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶\"\"\"\n",
    "    valid_files = {}\n",
    "    filtered_tracks = []\n",
    "    \n",
    "    for track_id, file_info in audio_files_info.items():\n",
    "        # æ£€æŸ¥æ–‡ä»¶å¤§å°\n",
    "        if not (min_size_kb <= file_info['size_kb'] <= max_size_kb):\n",
    "            continue\n",
    "            \n",
    "        # æ£€æŸ¥æ˜¯å¦åœ¨track_dataä¸­å­˜åœ¨\n",
    "        if track_id not in track_data['track_id'].values:\n",
    "            continue\n",
    "            \n",
    "        # è·å–å¯¹åº”çš„trackä¿¡æ¯\n",
    "        track_row = track_data[track_data['track_id'] == track_id].iloc[0]\n",
    "        \n",
    "        # åˆå¹¶éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯å’Œå…ƒæ•°æ®\n",
    "        combined_info = {\n",
    "            'track_id': track_id,\n",
    "            'title': track_row['title'],\n",
    "            'genre_top': track_row['genre_top'],\n",
    "            'duration': track_row['duration'],\n",
    "            'listens': track_row['listens'],\n",
    "            'audio_path': file_info['path'],\n",
    "            'file_size_kb': file_info['size_kb'],\n",
    "            'file_size_mb': file_info['size_mb']\n",
    "        }\n",
    "        \n",
    "        valid_files[track_id] = file_info\n",
    "        filtered_tracks.append(combined_info)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºDataFrame\n",
    "    valid_tracks_df = pd.DataFrame(filtered_tracks)\n",
    "    \n",
    "    print(f\"\\nâœ… è¿‡æ»¤ç»“æœ:\")\n",
    "    print(f\"   åŸå§‹track_data: {len(track_data)}\")\n",
    "    print(f\"   æœ€ç»ˆå¯ç”¨æ•°æ®: {len(valid_tracks_df)}\")\n",
    "    \n",
    "    return valid_tracks_df, valid_files\n",
    "\n",
    "# è¿‡æ»¤å¯ç”¨æ–‡ä»¶\n",
    "valid_tracks_df, valid_audio_files = filter_valid_audio_files(\n",
    "    audio_files_info, track_data, min_size_kb=10, max_size_kb=20000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1616e5f-a548-47c8-8a24-4f98bcfe9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   æ€»æµæ´¾æ•°: 8\n",
      "   æ€»æ­Œæ›²æ•°: 7996\n",
      "    1. Hip-Hop        : 1000 ( 12.5%)\n",
      "    2. Pop            : 1000 ( 12.5%)\n",
      "    3. Folk           : 1000 ( 12.5%)\n",
      "    4. International  : 1000 ( 12.5%)\n",
      "    5. Instrumental   : 1000 ( 12.5%)\n",
      "    6. Experimental   :  999 ( 12.5%)\n",
      "    7. Rock           :  999 ( 12.5%)\n",
      "    8. Electronic     :  998 ( 12.5%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_genre_distribution(valid_tracks_df, genres):\n",
    "    \"\"\"åˆ†æå¯ç”¨æ•°æ®çš„æµæ´¾åˆ†å¸ƒ\"\"\"\n",
    "\n",
    "    # ç»Ÿè®¡æ¯ä¸ªæµæ´¾çš„æ­Œæ›²æ•°é‡\n",
    "    genre_counts = valid_tracks_df['genre_top'].value_counts()\n",
    "    \n",
    "    # è·å–æµæ´¾åç§°\n",
    "    genre_names = {}\n",
    "    for genre_id in genre_counts.index:\n",
    "        if genre_id in genres.index:\n",
    "            genre_names[genre_id] = genres.loc[genre_id, 'title']\n",
    "        else:\n",
    "            genre_names[genre_id] = f\"Unknown_{genre_id}\"\n",
    "    \n",
    "    # åˆ›å»ºæµæ´¾ç»Ÿè®¡\n",
    "    genre_stats_filtered = pd.DataFrame({\n",
    "        'genre_id': genre_counts.index,\n",
    "        'genre_name': [genre_names[gid] for gid in genre_counts.index],\n",
    "        'track_count': genre_counts.values,\n",
    "        'percentage': (genre_counts.values / len(valid_tracks_df) * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    print(f\"   æ€»æµæ´¾æ•°: {len(genre_stats_filtered)}\")\n",
    "    print(f\"   æ€»æ­Œæ›²æ•°: {len(valid_tracks_df)}\")\n",
    "    for i, row in genre_stats_filtered.head(10).iterrows():\n",
    "        print(f\"   {i+1:2d}. {row['genre_name']:15s}: {row['track_count']:4d} ({row['percentage']:5.1f}%)\")\n",
    "    \n",
    "    return genre_stats_filtered\n",
    "\n",
    "# åˆ†æå¯ç”¨æ•°æ®çš„æµæ´¾åˆ†å¸ƒ\n",
    "if len(valid_tracks_df) > 0:\n",
    "    final_genre_stats = analyze_genre_distribution(valid_tracks_df, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a536b91-539c-4f8c-9491-46c35166938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(audio_path, sr=22050, n_mels=128, hop_length=512, n_fft=2048, duration=30):\n",
    "    \"\"\"\n",
    "    æå–melé¢‘è°±å›¾ç‰¹å¾\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # åŠ è½½éŸ³é¢‘ï¼Œé™åˆ¶æ—¶é•¿ä¸º30ç§’\n",
    "        y, sr = librosa.load(audio_path, sr=sr, duration=duration, offset=0)\n",
    "        \n",
    "        # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œç”¨é›¶å¡«å……åˆ°30ç§’\n",
    "        target_length = sr * duration\n",
    "        if len(y) < target_length:\n",
    "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
    "        else:\n",
    "            y = y[:target_length]\n",
    "        \n",
    "        # æå–melé¢‘è°±å›¾\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=n_mels, hop_length=hop_length, n_fft=n_fft\n",
    "        )\n",
    "        \n",
    "        # è½¬æ¢ä¸ºå¯¹æ•°åˆ»åº¦\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return mel_spec_db\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"å¤„ç†éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™ {audio_path}: {e}\")\n",
    "        # è¿”å›é›¶å¡«å……çš„é¢‘è°±å›¾\n",
    "        return np.zeros((n_mels, 1292))  # 30ç§’éŸ³é¢‘çš„é»˜è®¤æ—¶é—´å¸§æ•°\n",
    "\n",
    "def batch_extract_features(valid_tracks_df, batch_size=100, save_interval=500):\n",
    "    \"\"\"\n",
    "    æ‰¹é‡æå–ç‰¹å¾å¹¶ä¿å­˜åˆ°ç£ç›˜\n",
    "    \"\"\"\n",
    "    print(\"ğŸµ å¼€å§‹æ‰¹é‡æå–melé¢‘è°±å›¾ç‰¹å¾...\")\n",
    " \n",
    "    os.makedirs(FEATURE_PATH, exist_ok=True)\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    track_ids_list = []\n",
    "    \n",
    "    # åˆ›å»ºæ ‡ç­¾ç¼–ç å™¨\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # è·å–æ‰€æœ‰æµæ´¾IDå¹¶ç¼–ç \n",
    "    all_genres = valid_tracks_df['genre_top'].values\n",
    "    encoded_labels = label_encoder.fit_transform(all_genres)\n",
    "    \n",
    "    print(f\"æµæ´¾æ˜ å°„å…³ç³»:\")\n",
    "    for i, genre_id in enumerate(label_encoder.classes_):\n",
    "        genre_name = genres.loc[genre_id, 'title'] if genre_id in genres.index else f\"Unknown_{genre_id}\"\n",
    "        print(f\"   {i}: {genre_name} (ID: {genre_id})\")\n",
    "    \n",
    "    # éšæœºæ‰“ä¹±æ•°æ®\n",
    "    indices = np.random.permutation(len(valid_tracks_df))\n",
    "    \n",
    "    processed_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for idx in tqdm(indices, desc=\"æå–ç‰¹å¾\"):\n",
    "        row = valid_tracks_df.iloc[idx]\n",
    "        \n",
    "        # æå–melé¢‘è°±å›¾\n",
    "        mel_spec = extract_mel_spectrogram(row['audio_path'])\n",
    "        \n",
    "        if mel_spec is not None:\n",
    "            features_list.append(mel_spec)\n",
    "            labels_list.append(encoded_labels[idx])\n",
    "            track_ids_list.append(row['track_id'])\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            failed_count += 1\n",
    "        \n",
    "        # å®šæœŸä¿å­˜å’Œæ¸…ç†å†…å­˜\n",
    "        if len(features_list) >= save_interval:\n",
    "            print(f\"\\nğŸ’¾ ä¿å­˜ä¸­é—´ç»“æœ... (å·²å¤„ç†: {processed_count}, å¤±è´¥: {failed_count})\")\n",
    "            \n",
    "            # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜\n",
    "            features_array = np.array(features_list)\n",
    "            labels_array = np.array(labels_list)\n",
    "            track_ids_array = np.array(track_ids_list)\n",
    "            \n",
    "            # ä¿å­˜åˆ°æ–‡ä»¶\n",
    "            timestamp = int(time.time())\n",
    "            np.savez_compressed(os.path.join(FEATURE_PATH, f'features_batch_{timestamp}.npz'), \n",
    "                              features=features_array, \n",
    "                              labels=labels_array,\n",
    "                              track_ids=track_ids_array)\n",
    "            \n",
    "            # æ¸…ç†å†…å­˜\n",
    "            features_list = []\n",
    "            labels_list = []\n",
    "            track_ids_list = []\n",
    "    \n",
    "    # ä¿å­˜å‰©ä½™çš„æ•°æ®\n",
    "    if features_list:\n",
    "        print(f\"\\nğŸ’¾ ä¿å­˜æœ€åæ‰¹æ¬¡...\")\n",
    "        features_array = np.array(features_list)\n",
    "        labels_array = np.array(labels_list)\n",
    "        track_ids_array = np.array(track_ids_list)\n",
    "        \n",
    "        timestamp = int(time.time())\n",
    "        np.savez_compressed(os.path.join(FEATURE_PATH, f'features_batch_{timestamp}.npz'), \n",
    "                          features=features_array, \n",
    "                          labels=labels_array,\n",
    "                          track_ids=track_ids_array)\n",
    "    \n",
    "    print(f\"\\nç‰¹å¾æå–å®Œæˆ!\")\n",
    "    print(f\"   æˆåŠŸå¤„ç†: {processed_count} ä¸ªæ–‡ä»¶\")\n",
    "    print(f\"   å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶\")\n",
    "    \n",
    "    return label_encoder\n",
    "\n",
    "# test_data = valid_tracks_df.head(100)  # åªå¤„ç†å‰100ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•\n",
    "# label_encoder = batch_extract_features(test_data, batch_size=50, save_interval=50)\n",
    "\n",
    "# å·²ç»æå–è¿‡\n",
    "# label_encoder = batch_extract_features(valid_tracks_df, batch_size=100, save_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7249ad17-3087-4d8a-b4d1-e32c905a9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_features():\n",
    "    \"\"\"\n",
    "    åŠ è½½æ‰€æœ‰ä¿å­˜çš„ç‰¹å¾æ–‡ä»¶\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ğŸ“‚ åŠ è½½æ‰€æœ‰ç‰¹å¾æ–‡ä»¶...\")\n",
    "\n",
    "    feature_files = glob.glob(os.path.join(FEATURE_PATH, 'features_*.npz'))\n",
    "    if not feature_files:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°ç‰¹å¾æ–‡ä»¶ï¼\")\n",
    "        return None, None, None\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_track_ids = []\n",
    "    \n",
    "    for file in feature_files:\n",
    "        print(f\"   åŠ è½½: {file}\")\n",
    "        data = np.load(file)\n",
    "        all_features.append(data['features'])\n",
    "        all_labels.append(data['labels'])\n",
    "        all_track_ids.append(data['track_ids'])\n",
    "    \n",
    "    # åˆå¹¶æ‰€æœ‰æ•°æ®\n",
    "    features = np.concatenate(all_features, axis=0)\n",
    "    labels = np.concatenate(all_labels, axis=0)\n",
    "    track_ids = np.concatenate(all_track_ids, axis=0)\n",
    "    \n",
    "    print(f\"âœ… åŠ è½½å®Œæˆ!\")\n",
    "    print(f\"   æ€»æ ·æœ¬æ•°: {len(features)}\")\n",
    "    print(f\"   ç‰¹å¾ç»´åº¦: {features.shape}\")\n",
    "    print(f\"   æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(labels)}\")\n",
    "    \n",
    "    return features, labels, track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3ad512-6808-4a88-b865-995506f58c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # è½¬æ¢ä¸ºå¼ é‡\n",
    "        feature = torch.FloatTensor(feature).unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦\n",
    "        label = torch.LongTensor([label])[0]\n",
    "        \n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "        \n",
    "        return feature, label\n",
    "\n",
    "def create_data_splits(features, labels, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ åˆ’åˆ†æ•°æ®é›†...\")\n",
    "    \n",
    "    # é¦–å…ˆåˆ†ç¦»å‡ºæµ‹è¯•é›†\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        features, labels, test_size=test_size, \n",
    "        random_state=random_state, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # ä»å‰©ä½™æ•°æ®ä¸­åˆ†ç¦»å‡ºéªŒè¯é›†\n",
    "    val_size_adjusted = val_size / (1 - test_size)  # è°ƒæ•´éªŒè¯é›†æ¯”ä¾‹\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_size_adjusted, \n",
    "        random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ:\")\n",
    "    print(f\"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ ({len(X_train)/len(features)*100:.1f}%)\")\n",
    "    print(f\"   éªŒè¯é›†: {len(X_val)} æ ·æœ¬ ({len(X_val)/len(features)*100:.1f}%)\")\n",
    "    print(f\"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬ ({len(X_test)/len(features)*100:.1f}%)\")\n",
    "    \n",
    "    # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ\n",
    "    print(f\"\\nğŸ“Š å„é›†åˆçš„æ ‡ç­¾åˆ†å¸ƒ:\")\n",
    "    print(f\"   è®­ç»ƒé›†: {np.bincount(y_train)}\")\n",
    "    print(f\"   éªŒè¯é›†: {np.bincount(y_val)}\")\n",
    "    print(f\"   æµ‹è¯•é›†: {np.bincount(y_test)}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871b7794-734e-427f-aa3f-fb50e9b2ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ åŠ è½½æ‰€æœ‰ç‰¹å¾æ–‡ä»¶...\n",
      "   åŠ è½½: features\\features_batch_1754283560.npz\n",
      "   åŠ è½½: features\\features_batch_1754283609.npz\n",
      "   åŠ è½½: features\\features_batch_1754283656.npz\n",
      "   åŠ è½½: features\\features_batch_1754283721.npz\n",
      "   åŠ è½½: features\\features_batch_1754283766.npz\n",
      "   åŠ è½½: features\\features_batch_1754283828.npz\n",
      "   åŠ è½½: features\\features_batch_1754283986.npz\n",
      "   åŠ è½½: features\\features_batch_1754284160.npz\n",
      "   åŠ è½½: features\\features_batch_1754284344.npz\n",
      "   åŠ è½½: features\\features_batch_1754284508.npz\n",
      "   åŠ è½½: features\\features_batch_1754284602.npz\n",
      "   åŠ è½½: features\\features_batch_1754284667.npz\n",
      "   åŠ è½½: features\\features_batch_1754284712.npz\n",
      "   åŠ è½½: features\\features_batch_1754284758.npz\n",
      "   åŠ è½½: features\\features_batch_1754284804.npz\n",
      "   åŠ è½½: features\\features_batch_1754284850.npz\n",
      "   åŠ è½½: features\\features_batch_1754285711.npz\n",
      "âœ… åŠ è½½å®Œæˆ!\n",
      "   æ€»æ ·æœ¬æ•°: 8496\n",
      "   ç‰¹å¾ç»´åº¦: (8496, 128, 1292)\n",
      "   æ ‡ç­¾åˆ†å¸ƒ: [1065 1064 1066 1059 1061 1059 1062 1060]\n",
      "ğŸ”„ åˆ’åˆ†æ•°æ®é›†...\n",
      "âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ:\n",
      "   è®­ç»ƒé›†: 5946 æ ·æœ¬ (70.0%)\n",
      "   éªŒè¯é›†: 850 æ ·æœ¬ (10.0%)\n",
      "   æµ‹è¯•é›†: 1700 æ ·æœ¬ (20.0%)\n",
      "\n",
      "ğŸ“Š å„é›†åˆçš„æ ‡ç­¾åˆ†å¸ƒ:\n",
      "   è®­ç»ƒé›†: [745 745 746 741 743 741 743 742]\n",
      "   éªŒè¯é›†: [107 106 107 106 106 106 106 106]\n",
      "   æµ‹è¯•é›†: [213 213 213 212 212 212 213 212]\n",
      "âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®å¢å¼º\n",
    "class AudioTransform:\n",
    "    def __init__(self, noise_factor=0.005, time_shift_factor=0.1):\n",
    "        self.noise_factor = noise_factor\n",
    "        self.time_shift_factor = time_shift_factor\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # æ·»åŠ å™ªå£°\n",
    "        if random.random() > 0.5:\n",
    "            noise = torch.randn_like(x) * self.noise_factor\n",
    "            x = x + noise\n",
    "        \n",
    "        # æ—¶é—´åç§»\n",
    "        if random.random() > 0.5:\n",
    "            shift = int(x.shape[-1] * self.time_shift_factor * (random.random() - 0.5))\n",
    "            if shift != 0:\n",
    "                if shift > 0:\n",
    "                    x = torch.cat([x[..., shift:], torch.zeros_like(x[..., :shift])], dim=-1)\n",
    "                else:\n",
    "                    x = torch.cat([torch.zeros_like(x[..., :abs(shift)]), x[..., :shift]], dim=-1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# åŠ è½½ç‰¹å¾æ•°æ®\n",
    "features, labels, track_ids = load_all_features()\n",
    "\n",
    "if features is not None:\n",
    "    # åˆ’åˆ†æ•°æ®é›†\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = create_data_splits(features, labels)\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    train_transform = AudioTransform()  # è®­ç»ƒæ—¶ä½¿ç”¨æ•°æ®å¢å¼º\n",
    "    \n",
    "    train_dataset = MusicDataset(X_train, y_train, transform=train_transform)\n",
    "    val_dataset = MusicDataset(X_val, y_val, transform=None)\n",
    "    test_dataset = MusicDataset(X_test, y_test, transform=None)\n",
    "    \n",
    "    print(\"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed849e4b-3ada-4c47-a6b8-d1d3c5498115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # ç¬¬ä¸€å±‚\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # ç¬¬äºŒå±‚\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # ç¬¬ä¸‰å±‚\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # ç¬¬å››å±‚\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # è‡ªé€‚åº”æ± åŒ–\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        \n",
    "        # åˆ†ç±»å™¨\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
    "print(\"ğŸ—ï¸  åˆ›å»ºCNNæ¨¡å‹...\")\n",
    "model = CNN(num_classes=8)\n",
    "print(f\"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"\\nğŸ“‹ æ¨¡å‹ç»“æ„:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955bcb5-3a2d-474f-92ad-a3d3deee0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        with torch.no_grad():  \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"éªŒè¯ä¸€ä¸ªepoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # æŸå¤±æ›²çº¿\n",
    "    ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "    ax1.plot(val_losses, label='Validation Loss', color='red')\n",
    "    ax1.set_title('Loss vs Epoch')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # å‡†ç¡®ç‡æ›²çº¿\n",
    "    ax2.plot(train_accs, label='Training Accuracy', color='blue')\n",
    "    ax2.plot(val_accs, label='Validation Accuracy', color='red')\n",
    "    ax2.set_title('Accuracy vs Epoch')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"æ—©åœæœºåˆ¶\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a40a9-1378-4178-bd73-385103a08096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs=50, device='cuda', patience=10):\n",
    "    \"\"\"å®Œæ•´çš„è®­ç»ƒæµç¨‹\"\"\"\n",
    "    \n",
    "    print(f\"ğŸš€ å¼€å§‹è®­ç»ƒï¼Œå…± {num_epochs} ä¸ªepoch...\")\n",
    "    \n",
    "    # åˆå§‹åŒ–è®°å½•\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # æ—©åœæœºåˆ¶\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=0.001)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # è®­ç»ƒ\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # éªŒè¯\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # è°ƒæ•´å­¦ä¹ ç‡\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # æ‰“å°ç»“æœ\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_music_model.pth')\n",
    "            print(f\"ğŸ¯ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if early_stopping(val_loss, model):\n",
    "            print(f\"â¹ï¸  æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} ä¸ªepochåœæ­¢è®­ç»ƒ\")\n",
    "            break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "    print(f\"â±ï¸  è®­ç»ƒæ—¶é—´: {training_time/60:.2f} åˆ†é’Ÿ\")\n",
    "    print(f\"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87071f3a-0f05-4ed7-bc69-403fcb79f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ä¼˜åŒ–å™¨ - ä½¿ç”¨ç»å…¸é…ç½®\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=0.001,           # æ ‡å‡†å­¦ä¹ ç‡\n",
    "    weight_decay=1e-4   # L2æ­£åˆ™åŒ–\n",
    ")\n",
    "\n",
    "# å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1.0)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,           \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True         # åŠ é€ŸGPUä¼ è¾“\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,          \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"å‡†å¤‡åŸºçº¿æ¨¡å‹\")\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66846a-e0cc-43f6-844d-5ac153d240ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "class ConfigurableCNN(nn.Module):\n",
    "    \"\"\"å¯é…ç½®çš„CNNæ¨¡å‹ï¼Œç”¨äºè¶…å‚æ•°è°ƒä¼˜\"\"\"\n",
    "    \n",
    "    def __init__(self, trial, num_classes=8):\n",
    "        super(ConfigurableCNN, self).__init__()\n",
    "        \n",
    "        # é€šè¿‡trialå¯¹è±¡è·å–è¶…å‚æ•°\n",
    "        self.n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            # æ¯å±‚çš„é€šé“æ•°\n",
    "            out_channels = trial.suggest_categorical(f'n_units_l{i}', [16, 32, 64, 128, 256])\n",
    "            \n",
    "            # å·ç§¯æ ¸å¤§å°\n",
    "            kernel_size = trial.suggest_categorical(f'kernel_size_l{i}', [3, 5])\n",
    "            \n",
    "            # Dropoutæ¦‚ç‡\n",
    "            dropout_rate = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n",
    "            \n",
    "            # æ„å»ºå·ç§¯å—\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                nn.Dropout2d(dropout_rate)\n",
    "            ])\n",
    "            \n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        # è‡ªé€‚åº”æ± åŒ–\n",
    "        pool_size = trial.suggest_categorical('pool_size', [2, 4, 8])\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((pool_size, pool_size))\n",
    "        \n",
    "        # åˆ†ç±»å™¨\n",
    "        fc_input_size = in_channels * pool_size * pool_size\n",
    "        hidden_size = trial.suggest_categorical('fc_hidden_size', [128, 256, 512])\n",
    "        final_dropout = trial.suggest_float('final_dropout', 0.2, 0.7)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(final_dropout),\n",
    "            nn.Linear(fc_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(final_dropout * 0.5),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85943ebd-9b3c-4822-83a8-17de8a35713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optunaçš„ç›®æ ‡å‡½æ•°\"\"\"\n",
    "    \n",
    "    # 1. æ¨¡å‹è¶…å‚æ•°\n",
    "    model = ConfigurableCNN(trial, num_classes=8).to(device)\n",
    "    \n",
    "    # 2. è®­ç»ƒè¶…å‚æ•°\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    \n",
    "    # 3. ä¼˜åŒ–å™¨é€‰æ‹©\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "    \n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:  # SGD\n",
    "        momentum = trial.suggest_float('momentum', 0.8, 0.99)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "    \n",
    "    # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨æ–°çš„batch_sizeï¼‰\n",
    "    if 'train_dataset' in globals():\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    else:\n",
    "        # å¦‚æœæ•°æ®é›†ä¸å­˜åœ¨ï¼Œè¿”å›ä¸€ä¸ªè™šæ‹Ÿå€¼ç”¨äºæ¼”ç¤º\n",
    "        return 0.5\n",
    "    \n",
    "    # 5. è®­ç»ƒé…ç½®\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    n_epochs = 10  # ä¸ºäº†å¿«é€Ÿè°ƒä¼˜ï¼Œå‡å°‘epochæ•°\n",
    "    \n",
    "    # 6. è®­ç»ƒå¾ªç¯\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # è®­ç»ƒ\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx > 50:  # é™åˆ¶æ¯ä¸ªepochçš„æ‰¹æ¬¡æ•°ï¼ŒåŠ é€Ÿè°ƒä¼˜\n",
    "                break\n",
    "                \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # éªŒè¯\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                if batch_idx > 20:  # é™åˆ¶éªŒè¯æ‰¹æ¬¡æ•°\n",
    "                    break\n",
    "                    \n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "        \n",
    "        # æŠ¥å‘Šä¸­é—´ç»“æœç»™Optuna\n",
    "        trial.report(val_acc, epoch)\n",
    "        \n",
    "        # å¦‚æœæ•ˆæœä¸å¥½ï¼Œæå‰å‰ªæ\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return best_val_acc\n",
    "\n",
    "def run_hyperparameter_tuning(n_trials=50):\n",
    "    \"\"\"è¿è¡Œè¶…å‚æ•°è°ƒä¼˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” å¼€å§‹è¶…å‚æ•°è‡ªåŠ¨è°ƒä¼˜...\")\n",
    "    print(f\"å°†å°è¯• {n_trials} ç§ä¸åŒçš„è¶…å‚æ•°ç»„åˆ\")\n",
    "    \n",
    "    # åˆ›å»ºç ”ç©¶å¯¹è±¡\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',  # æœ€å¤§åŒ–éªŒè¯å‡†ç¡®ç‡\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "    )\n",
    "    \n",
    "    # å¼€å§‹ä¼˜åŒ–\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # è¾“å‡ºç»“æœ\n",
    "    print(\"ğŸ¯ è¶…å‚æ•°è°ƒä¼˜å®Œæˆï¼\")\n",
    "    print(f\"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {study.best_value:.4f}\")\n",
    "    print(\"æœ€ä½³è¶…å‚æ•°ç»„åˆ:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacd19a-69fc-44f7-948b-fbbcccd31646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_grid_search():\n",
    "    \"\"\"æ‰‹åŠ¨ç½‘æ ¼æœç´¢ï¼ˆæ›´ç®€å•çš„è°ƒå‚æ–¹æ³•ï¼‰\"\"\"\n",
    "    \n",
    "    if 'train_dataset' not in globals():\n",
    "        print(\"âš ï¸  è¯·å…ˆè¿è¡Œæ•°æ®åŠ è½½æ­¥éª¤ï¼\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ” å¼€å§‹æ‰‹åŠ¨ç½‘æ ¼æœç´¢...\")\n",
    "    \n",
    "    # å®šä¹‰æœç´¢ç©ºé—´\n",
    "    param_grid = {\n",
    "        'lr': [0.001, 0.0005, 0.0001],\n",
    "        'batch_size': [16, 32, 64],\n",
    "        'weight_decay': [1e-4, 1e-5, 1e-6],\n",
    "        'dropout_rate': [0.3, 0.4, 0.5]\n",
    "    }\n",
    "    \n",
    "    best_params = None\n",
    "    best_acc = 0.0\n",
    "    results = []\n",
    "    \n",
    "    # éå†æ‰€æœ‰å‚æ•°ç»„åˆ\n",
    "    from itertools import product\n",
    "    \n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    print(f\"æ€»å…±éœ€è¦æµ‹è¯• {total_combinations} ç§å‚æ•°ç»„åˆ\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        lr, batch_size, weight_decay, dropout_rate = params\n",
    "        \n",
    "        print(f\"\\næµ‹è¯•ç»„åˆ {i+1}/{total_combinations}:\")\n",
    "        print(f\"  lr={lr}, batch_size={batch_size}, weight_decay={weight_decay}, dropout={dropout_rate}\")\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        model = DeepMusicCNN(num_classes=8).to(device)\n",
    "        \n",
    "        # ä¿®æ”¹dropoutç‡ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Dropout) or isinstance(module, nn.Dropout2d):\n",
    "                module.p = dropout_rate\n",
    "        \n",
    "        # åˆ›å»ºä¼˜åŒ–å™¨\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        \n",
    "        # å¿«é€Ÿè®­ç»ƒï¼ˆåªè®­ç»ƒå‡ ä¸ªepochï¼‰\n",
    "        best_val_acc = 0.0\n",
    "        for epoch in range(5):  # åªè®­ç»ƒ5ä¸ªepoch\n",
    "            # è®­ç»ƒ\n",
    "            model.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                if batch_idx > 30:  # é™åˆ¶æ‰¹æ¬¡æ•°\n",
    "                    break\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # éªŒè¯\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                    if batch_idx > 15:  # é™åˆ¶éªŒè¯æ‰¹æ¬¡æ•°\n",
    "                        break\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    output = model(data)\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "            \n",
    "            val_acc = correct / total\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "        \n",
    "        results.append({\n",
    "            'params': {'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'dropout': dropout_rate},\n",
    "            'accuracy': best_val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}\")\n",
    "        \n",
    "        if best_val_acc > best_acc:\n",
    "            best_acc = best_val_acc\n",
    "            best_params = {'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay, 'dropout': dropout_rate}\n",
    "            print(f\"  ğŸ¯ å‘ç°æ›´å¥½çš„å‚æ•°ç»„åˆï¼\")\n",
    "    \n",
    "    print(f\"\\nâœ… ç½‘æ ¼æœç´¢å®Œæˆï¼\")\n",
    "    print(f\"æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}\")\n",
    "    print(\"æœ€ä½³å‚æ•°:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return best_params, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc13dbf-c36f-4aad-a3fc-acd6e8962be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hyperparameter_tuning(n_trials=20)\n",
    "\n",
    "manual_grid_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
